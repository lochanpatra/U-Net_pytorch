# -*- coding: utf-8 -*-
"""Mumbai_road_Pytorch UNET Mode.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NCGfnyVVNvoas-JxilAnlyw79olscsfb



import os
import numpy as np
import geopandas as gpd
from shapely.geometry import box, LineString, MultiLineString
from PIL import Image, ImageDraw
import matplotlib.pyplot as plt

# Load the full road GeoJSON once
roads_gdf = gpd.read_file("mumbai_roads.geojson")

# Overall bounding box (should cover your entire roads data)
west, south, east, north = 72.77, 18.96, 72.91, 19.10

# Grid parameters
n_x, n_y = 4, 4  # number of tiles horizontally and vertically
img_size = (512, 512)
output_dir = "mumbai_road_masks_multi"
os.makedirs(output_dir, exist_ok=True)

# Generate grid bounding boxes (tiles)
def generate_grid(west, south, east, north, n_x, n_y):
    lon_steps = np.linspace(west, east, n_x + 1)
    lat_steps = np.linspace(south, north, n_y + 1)
    grid = []
    for i in range(n_x):
        for j in range(n_y):
            tile_bbox = (lon_steps[i], lat_steps[j], lon_steps[i+1], lat_steps[j+1])  # west, south, east, north
            grid.append(tile_bbox)
    return grid

grid_cells = generate_grid(west, south, east, north, n_x, n_y)

def lonlat_to_pixel(x, y, bounds, size):
    minx, miny, maxx, maxy = bounds
    px = int((x - minx) / (maxx - minx) * size[0])
    py = int((maxy - y) / (maxy - miny) * size[1])  # flip y axis
    return (px, py)

for i, (w, s, e, n) in enumerate(grid_cells):
    print(f"Processing tile {i}: bbox (W:{w}, S:{s}, E:{e}, N:{n})")

    # Create bounding box polygon for clipping
    tile_poly = box(w, s, e, n)

    # Clip roads to tile bbox
    clipped_roads = roads_gdf[roads_gdf.intersects(tile_poly)].copy()
    clipped_roads = clipped_roads.clip(tile_poly)

    if clipped_roads.empty:
        print(f"Tile {i} has no roads, saving empty mask.")
        mask = Image.new("L", img_size, 0)
        mask.save(os.path.join(output_dir, f"tile_{i}_mask.png"))
        continue

    # Get bounds of clipped roads for pixel projection
    minx, miny, maxx, maxy = clipped_roads.total_bounds

    # Create blank mask
    mask = Image.new("L", img_size, 0)
    draw = ImageDraw.Draw(mask)

# Draw roads
    for geom in clipped_roads.geometry:
        if isinstance(geom, LineString):
            coords = [lonlat_to_pixel(x, y, (minx, miny, maxx, maxy), img_size) for x, y in geom.coords]
            draw.line(coords, fill=255, width=3)
        elif isinstance(geom, MultiLineString):
            for line in geom.geoms:
                coords = [lonlat_to_pixel(x, y, (minx, miny, maxx, maxy), img_size) for x, y in line.coords]
                draw.line(coords, fill=255, width=3)

    # Save mask image
    mask_path = os.path.join(output_dir, f"tile_{i}_mask.png")
    mask.save(mask_path)
    print(f"Saved mask for tile {i} to {mask_path}")

    # Optional: visualize the first tile
    if i == 0:
        plt.imshow(np.array(mask), cmap='gray')
        plt.title(f"Tile {i} Road Mask")
        plt.axis('off')
        plt.show()

"""Visualise from folder"""

import matplotlib.pyplot as plt
import os
from PIL import Image
import numpy as np

output_dir = "mumbai_road_masks_multi"

# Choose which tiles to visualize (you can change these indices)
tiles_to_plot = [0, 5, 10, 14, 15]

plt.figure(figsize=(15, 3))
for idx, tile_i in enumerate(tiles_to_plot):
    mask_path = os.path.join(output_dir, f"tile_{tile_i}_mask.png")
    mask_img = Image.open(mask_path)
    plt.subplot(1, len(tiles_to_plot), idx + 1)
    plt.imshow(np.array(mask_img), cmap='gray')
    plt.title(f"Tile {tile_i}")
    plt.axis('off')

plt.tight_layout()
plt.show()

pip install rasterio

import os
import numpy as np
import geopandas as gpd
from shapely.geometry import box, LineString, MultiLineString
from PIL import Image, ImageDraw
import rasterio
from rasterio.windows import from_bounds
import matplotlib.pyplot as plt

# Parameters
large_sat_path = "/content/mumbai_satellite_tiles/mumbai_tile.tif"       # Your big satellite GeoTIFF
roads_geojson = "mumbai_roads.geojson"       # Your full roads GeoJSON
output_sat_dir = "sat_tiles"
output_mask_dir = "road_masks"
os.makedirs(output_sat_dir, exist_ok=True)
os.makedirs(output_mask_dir, exist_ok=True)

# Define bounding box and grid
west, south, east, north = 72.77, 18.96, 72.91, 19.10
n_x, n_y = 4, 4
img_size = (512, 512)  # output tile size

def generate_grid(west, south, east, north, n_x, n_y):
    lon_steps = np.linspace(west, east, n_x + 1)
    lat_steps = np.linspace(south, north, n_y + 1)
    grid = []
    for i in range(n_x):
        for j in range(n_y):
            tile_bbox = (lon_steps[i], lat_steps[j], lon_steps[i+1], lat_steps[j+1])
            grid.append(tile_bbox)
    return grid

grid_cells = generate_grid(west, south, east, north, n_x, n_y)

# Load roads and reproject if needed
roads_gdf = gpd.read_file(roads_geojson)
if roads_gdf.crs != "EPSG:4326":
    roads_gdf = roads_gdf.to_crs(epsg=4326)

def lonlat_to_pixel(x, y, bounds, size):
    minx, miny, maxx, maxy = bounds
    px = int((x - minx) / (maxx - minx) * size[0])
    py = int((maxy - y) / (maxy - miny) * size[1])  # flipped y axis for image coords
    return (px, py)

with rasterio.open(large_sat_path) as src:
    for i, (w, s, e, n) in enumerate(grid_cells):
        print(f"Processing tile {i}: bbox (W:{w}, S:{s}, E:{e}, N:{n})")
        tile_box = box(w, s, e, n)

        # 1. Crop satellite image tile
        window = from_bounds(w, s, e, n, src.transform)
        tile_img = src.read(window=window)  # shape: (bands, height, width)

        # Convert to HWC and normalize/swap bands if needed
        tile_img = np.transpose(tile_img, (1, 2, 0))
        tile_img = np.clip(tile_img, 0, 255).astype(np.uint8)

        # Resize to fixed size if needed
        tile_pil = Image.fromarray(tile_img).resize(img_size)
        tile_pil.save(os.path.join(output_sat_dir, f"tile_{i}_sat.png"))

        # 2. Clip roads to tile bbox
        clipped_roads = roads_gdf[roads_gdf.intersects(tile_box)].copy()
        clipped_roads = clipped_roads.clip(tile_box)

        # Create blank mask
        mask = Image.new("L", img_size, 0)
        draw = ImageDraw.Draw(mask)

        if not clipped_roads.empty:
            # Use bounds of clipped roads for pixel coords
            minx, miny, maxx, maxy = clipped_roads.total_bounds

            for geom in clipped_roads.geometry:
                if isinstance(geom, LineString):
                    coords = [lonlat_to_pixel(x, y, (minx, miny, maxx, maxy), img_size) for x, y in geom.coords]
                    draw.line(coords, fill=255, width=3)
                elif isinstance(geom, MultiLineString):
                    for line in geom.geoms:
                        coords = [lonlat_to_pixel(x, y, (minx, miny, maxx, maxy), img_size) for x, y in line.coords]
                        draw.line(coords, fill=255, width=3)
        else:
            print(f"Tile {i} has no roads, saving empty mask.")

        mask.save(os.path.join(output_mask_dir, f"tile_{i}_mask.png"))

print("Done cropping satellite tiles and generating masks.")



"""1. Visual Debug: Overlay Road Mask on Satellite Tile"""

import matplotlib.pyplot as plt
from PIL import Image
import numpy as np

# Replace with your tile index
tile_idx = 13

# Load satellite image and mask
img = Image.open(f"{output_sat_dir}/tile_{tile_idx}_sat.png").convert("RGB")
mask = Image.open(f"{output_mask_dir}/tile_{tile_idx}_mask.png").convert("L")

# Convert to NumPy
img_np = np.array(img)
mask_np = np.array(mask)

# Plot overlay
plt.figure(figsize=(6, 6))
plt.imshow(img_np)
plt.imshow(mask_np, cmap='Reds', alpha=0.4)
plt.title(f"Tile {tile_idx} – Visual Alignment Check")
plt.axis('off')
plt.show()

"""2. Programmatic Check: Percentage of Road Pixels"""

mask_arr = np.array(mask)
road_pixels = np.sum(mask_arr > 0)
total_pixels = mask_arr.size
percent = road_pixels / total_pixels * 100

print(f"Tile {i} – Road pixels: {road_pixels} ({percent:.2f}%)")

"""3. (Optional) Debug Individual Coordinate Transforms"""

for geom in clipped_roads.geometry:
    if isinstance(geom, LineString):
        for x, y in geom.coords:
            px, py = lonlat_to_pixel(x, y, (w, s, e, n), img_size)
            print(f"Road coord: ({x:.6f}, {y:.6f}) -> Pixel: ({px}, {py})")



"""for bulk tiles"""

output_sat_dir = "sat_tiles"       # directory with tile_XX_sat.png
output_mask_dir = "road_masks"     # directory with tile_XX_mask.png
overlay_dir = "overlay_tiles"
os.makedirs(overlay_dir, exist_ok=True)

n_tiles = 16  # or however many tiles you generated

"""Overlay and Save Tiles in Bulk"""

from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
import os

# Paths
n_tiles = 16  # update based on your grid
for i in range(n_tiles):
    sat_path = os.path.join(output_sat_dir, f"tile_{i}_sat.png")
    mask_path = os.path.join(output_mask_dir, f"tile_{i}_mask.png")
    overlay_path = os.path.join(overlay_dir, f"tile_{i}_overlay.png")

    if not (os.path.exists(sat_path) and os.path.exists(mask_path)):
        print(f"Skipping tile {i}, missing files.")
        continue

    # Load images
    sat = Image.open(sat_path).convert("RGB")
    mask = Image.open(mask_path).convert("L")
    sat_np = np.array(sat)
    mask_np = np.array(mask)

    # Overlay mask as red
    overlay = sat_np.copy()
    overlay[mask_np > 0] = [255, 0, 0]  # red where roads exist

    # Side-by-side view
    combined = np.hstack([sat_np, overlay])

    # Save overlay image
    overlay_img = Image.fromarray(combined)
    overlay_img.save(overlay_path)

    # Print debug info
    road_pixels = np.sum(mask_np > 0)
    total_pixels = mask_np.size
    percent = road_pixels / total_pixels * 100
    print(f"Tile {i} – Road pixels: {road_pixels} ({percent:.2f}%)")
    print(f"  Saved: {overlay_path}")

"""visual overlay tiles"""

import matplotlib.pyplot as plt
from PIL import Image
import numpy as np
import os

output_sat_dir = "sat_tiles"
output_mask_dir = "road_masks"

def overlay_mask_on_satellite(tile_idx):
    sat_path = os.path.join(output_sat_dir, f"tile_{tile_idx}_sat.png")
    mask_path = os.path.join(output_mask_dir, f"tile_{tile_idx}_mask.png")

    sat_img = Image.open(sat_path).convert("RGB")
    mask_img = Image.open(mask_path).convert("L")

    sat_np = np.array(sat_img)
    mask_np = np.array(mask_img)

    # Create an RGBA overlay for mask (red color with alpha)
    red_overlay = np.zeros((mask_np.shape[0], mask_np.shape[1], 4), dtype=np.uint8)
    red_overlay[..., 0] = 255   # red channel
    red_overlay[..., 3] = (mask_np > 0) * 120  # alpha channel for visible mask pixels

    plt.figure(figsize=(6,6))
    plt.imshow(sat_np)
    plt.imshow(red_overlay)
    plt.title(f"Satellite Tile {tile_idx} with Road Mask Overlay")
    plt.axis('off')
    plt.show()

# Visualize a few tiles, e.g. 0, 5, 10
for idx in [0, 5, 10]:
    overlay_mask_on_satellite(idx)

import matplotlib.pyplot as plt
from PIL import Image
import numpy as np
import os

output_sat_dir = "sat_tiles"
output_mask_dir = "road_masks"

def overlay_mask_on_satellite(tile_idx):
    sat_path = os.path.join(output_sat_dir, f"tile_{tile_idx}_sat.png")
    mask_path = os.path.join(output_mask_dir, f"tile_{tile_idx}_mask.png")

    sat_img = Image.open(sat_path).convert("RGB")
    mask_img = Image.open(mask_path).convert("L")

    sat_np = np.array(sat_img)
    mask_np = np.array(mask_img)

    # Create a red semi-transparent overlay for mask
    red_overlay = np.zeros((mask_np.shape[0], mask_np.shape[1], 4), dtype=np.uint8)
    red_overlay[..., 0] = 255  # Red channel
    red_overlay[..., 3] = (mask_np > 0) * 120  # Alpha channel (transparency)

    return sat_np, red_overlay

def plot_tiles_grid(tile_indices, cols=4):
    rows = (len(tile_indices) + cols - 1) // cols
    fig, axes = plt.subplots(rows, cols, figsize=(4*cols, 4*rows))
    axes = axes.flatten()

    for ax, idx in zip(axes, tile_indices):
        sat_np, red_overlay = overlay_mask_on_satellite(idx)
        ax.imshow(sat_np)
        ax.imshow(red_overlay)
        ax.set_title(f"Tile {idx}")
        ax.axis('off')

    # Hide unused subplots
    for ax in axes[len(tile_indices):]:
        ax.axis('off')

    plt.tight_layout()
    plt.show()

# Example usage: visualize tiles 0 to 7 in a 4-column grid
plot_tiles_grid(tile_indices=list(range(8)), cols=4)

"""compare two tiles pixel"""

import matplotlib.pyplot as plt
from PIL import Image
import numpy as np
import os

mask_dir = "road_masks"

def load_mask(tile_idx):
    mask_path = os.path.join(mask_dir, f"tile_{tile_idx}_mask.png")
    mask_img = Image.open(mask_path).convert("L")
    mask_np = np.array(mask_img)
    return mask_np

def print_mask_stats(mask_np, tile_idx):
    road_pixels = np.sum(mask_np > 0)
    total_pixels = mask_np.size
    print(f"Tile {tile_idx} mask stats:")
    print(f"  Total pixels: {total_pixels}")
    print(f"  Road pixels: {road_pixels}")
    print(f"  Road pixel ratio: {road_pixels / total_pixels:.4f}")
    print()

def debug_two_masks(tile1_idx, tile2_idx):
    mask1 = load_mask(tile1_idx)
    mask2 = load_mask(tile2_idx)

    print_mask_stats(mask1, tile1_idx)
    print_mask_stats(mask2, tile2_idx)

    fig, axes = plt.subplots(1, 2, figsize=(10, 5))
    axes[0].imshow(mask1, cmap="gray")
    axes[0].set_title(f"Tile {tile1_idx} Mask")
    axes[0].axis("off")
    axes[1].imshow(mask2, cmap="gray")
    axes[1].set_title(f"Tile {tile2_idx} Mask")
    axes[1].axis("off")
    plt.show()

# Example usage: compare masks for tile 0 and tile 1
debug_two_masks(0, 1)

import os
import rasterio
from rasterio.windows import from_bounds
from rasterio.plot import reshape_as_image
from shapely.geometry import box
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt

# Settings
sat_path = "/content/mumbai_satellite_tiles/mumbai_tile.tif"
mask_dir = "mumbai_road_masks_multi"
output_cropped_dir = "cropped_sat_tiles"
output_overlay_dir = "overlay_tiles"
os.makedirs(output_cropped_dir, exist_ok=True)
os.makedirs(output_overlay_dir, exist_ok=True)

# Tile grid (same as before)
west, south, east, north = 72.77, 18.96, 72.91, 19.10
n_x, n_y = 4, 4

# Generate grid
def generate_grid(west, south, east, north, n_x, n_y):
    lon_steps = np.linspace(west, east, n_x + 1)
    lat_steps = np.linspace(south, north, n_y + 1)
    grid = []
    for i in range(n_y):
        for j in range(n_x):
            w_, e_ = lon_steps[j], lon_steps[j+1]
            s_, n_ = lat_steps[i], lat_steps[i+1]
            grid.append((w_, s_, e_, n_))
    return grid

grid_cells = generate_grid(west, south, east, north, n_x, n_y)

# Crop and overlay
with rasterio.open(sat_path) as src:
    for i, (w, s, e, n) in enumerate(grid_cells):
        print(f"Processing tile {i}...")

        # Crop tile from GeoTIFF
        window = from_bounds(w, s, e, n, transform=src.transform)
        img_tile = src.read(window=window)
        img_tile = reshape_as_image(img_tile)  # (H, W, C)

         # Convert from uint16 to uint8 if needed
        if img_tile.dtype == np.uint16:
            img_tile = ((img_tile / img_tile.max()) * 255).astype(np.uint8)

        img_tile = Image.fromarray(img_tile).convert("RGB")

        sat_tile_path = os.path.join(output_cropped_dir, f"tile_{i}_sat.png")
        img_tile.save(sat_tile_path)

        # Load mask
        mask_path = os.path.join(mask_dir, f"tile_{i}_mask.png")
        if not os.path.exists(mask_path):
            print(f"  No mask found for tile {i}")
            continue
        mask = Image.open(mask_path).convert("L").resize(img_tile.size)

        # Overlay mask in red
        overlay = img_tile.copy().convert("RGBA")
        mask_red = Image.new("RGBA", overlay.size, (255, 0, 0, 0))
        mask_np = np.array(mask)
        mask_alpha = (mask_np > 0).astype(np.uint8) * 100  # semi-transparent
        mask_rgba = np.array(mask_red)
        mask_rgba[..., 3] = mask_alpha
        mask_overlay = Image.alpha_composite(overlay, Image.fromarray(mask_rgba))

        # Save overlay image
        overlay_path = os.path.join(output_overlay_dir, f"tile_{i}_overlay.png")
        mask_overlay.save(overlay_path)
        print(f"  Saved: {overlay_path}")

        # Optional: show first few overlays
        if i < 2:
            plt.figure(figsize=(6, 6))
            plt.imshow(mask_overlay)
            plt.title(f"Overlay Tile {i}")
            plt.axis("off")
            plt.show()

import matplotlib.pyplot as plt
from PIL import Image

for i in range(13, 16):  # Tiles 13–15
    overlay_path = f"overlay_tiles/tile_{i}_overlay.png"
    img = Image.open(overlay_path)
    plt.figure(figsize=(6, 6))
    plt.imshow(img)
    plt.title(f"Tile {i} Overlay")
    plt.axis("off")
    plt.show()

for i in range(13, 16):
    mask_path = f"mumbai_road_masks_multi/tile_{i}_mask.png"
    mask = np.array(Image.open(mask_path))
    road_pixels = (mask > 0).sum()
    total = mask.size
    print(f"Tile {i} - Road pixels: {road_pixels} ({road_pixels/total:.2%})")

"""check no of tiles match"""

import os
import shutil
import numpy as np
from PIL import Image

# Directories
mask_dir = "mumbai_road_masks_multi"
sat_dir = "cropped_sat_tiles"
output_train_sat = "train/sat"
output_train_mask = "train/mask"
os.makedirs(output_train_sat, exist_ok=True)
os.makedirs(output_train_mask, exist_ok=True)

# Threshold for road pixel coverage
threshold = 0.05  # 5%

selected_tiles = []

for i in range(16):  # Assuming 4x4 grid
    mask_path = os.path.join(mask_dir, f"tile_{i}_mask.png")
    sat_path = os.path.join(sat_dir, f"tile_{i}_sat.png")

    if not os.path.exists(mask_path) or not os.path.exists(sat_path):
        continue

    mask = np.array(Image.open(mask_path))
    road_pixels = (mask > 0).sum()
    total_pixels = mask.size
    road_ratio = road_pixels / total_pixels

    if road_ratio >= threshold:
        selected_tiles.append((i, road_ratio))
        # Copy to training dirs
        shutil.copy(sat_path, os.path.join(output_train_sat, f"tile_{i}_sat.png"))
        shutil.copy(mask_path, os.path.join(output_train_mask, f"tile_{i}_mask.png"))

# Report selected tiles
print("Selected tiles for training (coverage ≥ {:.2%}):".format(threshold))
for i, ratio in selected_tiles:
    print(f"  Tile {i}: {ratio:.2%} road coverage")

print(f"\nTotal selected tiles: {len(selected_tiles)}")

import os
from PIL import Image

# Paths
sat_dir = "train/sat"
output_dir = "train/sat_resized"
mask_size = (512, 512)

os.makedirs(output_dir, exist_ok=True)

sat_files = [f for f in os.listdir(sat_dir) if f.endswith("_sat.png")]

for file in sat_files:
    input_path = os.path.join(sat_dir, file)
    output_path = os.path.join(output_dir, file)

    img = Image.open(input_path).convert("RGB")
    img_resized = img.resize(mask_size, Image.BILINEAR)
    img_resized.save(output_path)

    print(f"Resized and saved: {output_path}")

import matplotlib.pyplot as plt
import numpy as np

tile = "tile_15"  # or any other selected tile
img = np.array(Image.open(f"train/sat_resized/{tile}_sat.png"))
mask = np.array(Image.open(f"train/mask/{tile}_mask.png"))

plt.imshow(img)
plt.imshow(mask, cmap='Reds', alpha=0.4)  # overlay mask
plt.title(f"{tile} Overlay")
plt.axis('off')
plt.show()

import os
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import albumentations as A
from albumentations.pytorch import ToTensorV2

# Paths
input_dir = "train/sat_resized"
mask_dir = "train/mask"
input_files = sorted(os.listdir(input_dir))[:3]  # Show first 3 tiles

# Augmentation pipeline (for both image and mask)
aug = A.Compose([
    A.RandomCrop(width=256, height=256),
    A.HorizontalFlip(p=0.5),
    A.VerticalFlip(p=0.5),
    A.RandomRotate90(p=0.5),
    A.RandomBrightnessContrast(p=0.5),
    A.Normalize(),  # optional for U-Net training
], additional_targets={'mask': 'mask'})

# Show augmented batches
for file in input_files:
    image = np.array(Image.open(os.path.join(input_dir, file)).convert("RGB"))
    mask_file = file.replace("_sat.png", "_mask.png")
    mask = np.array(Image.open(os.path.join(mask_dir, mask_file)))

    plt.figure(figsize=(12, 3))
    for i in range(4):  # Show 4 augmented versions
        augmented = aug(image=image, mask=mask)
        img_aug, mask_aug = augmented['image'], augmented['mask']

        plt.subplot(2, 4, i + 1)
        plt.imshow(img_aug)
        plt.title("Augmented Image")
        plt.axis('off')

        plt.subplot(2, 4, i + 5)
        plt.imshow(mask_aug, cmap='gray')
        plt.title("Augmented Mask")
        plt.axis('off')
    plt.suptitle(file, fontsize=14)
    plt.tight_layout()
    plt.show()

"""PyTorch Dataset Class"""

# import os
# from PIL import Image
# from torch.utils.data import Dataset
# import torchvision.transforms as T

# class RoadSegmentationDataset(Dataset):
#     def __init__(self, image_dir, mask_dir, transform=None, mask_transform=None):
#         self.image_dir = image_dir
#         self.mask_dir = mask_dir
#         self.image_names = sorted(os.listdir(image_dir))
#         self.transform = transform
#         self.mask_transform = mask_transform

#     def __len__(self):
#         return len(self.image_names)

#     def __getitem__(self, idx):
#         img_name = self.image_names[idx]
#         img_path = os.path.join(self.image_dir, img_name)
#         mask_path = os.path.join(self.mask_dir, img_name)

#         image = Image.open(img_path).convert("RGB")
#         mask = Image.open(mask_path).convert("L")  # single channel

#         if self.transform:
#             image = self.transform(image)
#         if self.mask_transform:
#             mask = self.mask_transform(mask)

#         return image, mask

# from torch.utils.data import DataLoader
# import torchvision.transforms as T

# # Image and mask transforms
# img_transforms = T.Compose([
#     T.ToTensor(),
#     T.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
# ])
# mask_transforms = T.ToTensor()  # outputs float32 [0,1]

# # Dataset & loader
# # dataset = RoadSegmentationDataset("train/mask", "train/sat",
# #                                    transform=img_transforms,
# #                                    mask_transform=mask_transforms)

# dataloader = DataLoader(dataset, batch_size=4, shuffle=True)

# Correct path setup
dataset = RoadSegmentationDataset(
    image_dir="train/sat",     # Folder with satellite images
    mask_dir="train/mask",    # Folder with masks
    transform=img_transforms,
    mask_transform=mask_transforms
)

import os

sat_dir = "train/sat"
for fname in os.listdir(sat_dir):
    if fname.endswith("_sat.png"):
        new_name = fname.replace("_sat", "")
        os.rename(os.path.join(sat_dir, fname), os.path.join(sat_dir, new_name))
print("Renamed satellite files.")

def __getitem__(self, idx):
    img_name = self.image_names[idx]
    base_name = img_name.replace("_sat", "")

    img_path = os.path.join(self.image_dir, img_name)
    mask_path = os.path.join(self.mask_dir, base_name)

    image = Image.open(img_path).convert("RGB")
    mask = Image.open(mask_path).convert("L")

    ...

def __getitem__(self, idx):
    img_name = self.image_names[idx]

    # Remove '_sat' to get mask name
    base_name = img_name.replace("_sat", "").replace(".png", "") + "_mask.png"

    img_path = os.path.join(self.image_dir, img_name)
    mask_path = os.path.join(self.mask_dir, base_name)

    image = Image.open(img_path).convert("RGB")
    mask = Image.open(mask_path).convert("L")

    if self.transform:
        image = self.transform(image)
    if self.mask_transform:
        mask = self.mask_transform(mask)

    return image, mask

import os
print(os.listdir('train/sat'))
print(os.listdir('train/mask'))

from torch.utils.data import Dataset
from PIL import Image
import os

class RoadSegmentationDataset(Dataset):
    def __init__(self, image_dir, mask_dir, transform=None, mask_transform=None):
        self.image_dir = image_dir
        self.mask_dir = mask_dir
        self.transform = transform
        self.mask_transform = mask_transform

        # Only load image names that have corresponding masks
        self.image_names = sorted([
            f for f in os.listdir(image_dir)
            if os.path.exists(os.path.join(mask_dir, f.replace('.png', '_mask.png')))
        ])

    def __len__(self):
        return len(self.image_names)

    def __getitem__(self, idx):
        image_name = self.image_names[idx]
        mask_name = image_name.replace('.png', '_mask.png')

        image_path = os.path.join(self.image_dir, image_name)
        mask_path = os.path.join(self.mask_dir, mask_name)

        image = Image.open(image_path).convert("RGB")
        mask = Image.open(mask_path).convert("L")  # Grayscale

        if self.transform:
            image = self.transform(image)
        if self.mask_transform:
            mask = self.mask_transform(mask)

        return image, mask

from torchvision import transforms

image_transform = transforms.Compose([
    transforms.Resize((512, 512)),
    transforms.ToTensor(),  # Converts [0,255] to [0,1] float
])

mask_transform = transforms.Compose([
    transforms.Resize((512, 512)),
    transforms.ToTensor(),  # Converts to float tensor (0.0 or 1.0)
])

image_transform = transforms.Compose([
    transforms.Resize((512, 512)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # Standard ImageNet means
                         std=[0.229, 0.224, 0.225])
])

"""Sample Visual Check"""

dataset = RoadSegmentationDataset(
    image_dir='train/sat',
    mask_dir='train/mask',
    transform=image_transform,         # Define your torchvision transform
    mask_transform=mask_transform      # Optional: Resize, ToTensor, etc.
)

# Example preview
img, mask = dataset[0]

import matplotlib.pyplot as plt
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.imshow(img.permute(1, 2, 0))  # if ToTensor was applied
plt.title("Satellite")
plt.axis("off")

plt.subplot(1, 2, 2)
plt.imshow(mask.squeeze(), cmap='gray')
plt.title("Road Mask")
plt.axis("off")
plt.show()

for name in dataset.image_names:
    img_path = os.path.join(dataset.image_dir, name)
    mask_path = os.path.join(dataset.mask_dir, name)
    if not os.path.exists(mask_path):
        print(f"Missing mask for: {name}")

import matplotlib.pyplot as plt

img, mask = dataset[0]
plt.figure(figsize=(8,4))
plt.subplot(1,2,1)
plt.imshow(img.permute(1,2,0))  # CHW -> HWC
plt.title("Satellite Image")
plt.axis('off')
plt.subplot(1,2,2)
plt.imshow(mask.squeeze(), cmap='gray')  # CHW -> HWC
plt.title("Road Mask")
plt.axis('off')
plt.show()



"""training a segmentation model ( U-Net) in PyTorch"""

from torch.utils.data import DataLoader

train_loader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=2)

"""Define U-Net Model"""

pip install segmentation-models-pytorch

import segmentation_models_pytorch as smp

model = smp.Unet(encoder_name="resnet34", encoder_weights="imagenet", in_channels=3, classes=1)

"""Set Up Training Utilities"""

import torch
import torch.nn as nn
import torch.optim as optim

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

criterion = nn.BCEWithLogitsLoss()  # For binary mask
optimizer = optim.Adam(model.parameters(), lr=1e-4)

"""Training Loop (Basic Version)"""

num_epochs = 10

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0

    for images, masks in train_loader:
        images = images.to(device)
        masks = masks.to(device)

        outputs = model(images)
        loss = criterion(outputs, masks)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    print(f"Epoch {epoch+1}/{num_epochs} - Loss: {running_loss / len(train_loader):.4f}")

model.eval()
with torch.no_grad():
    for images, masks in train_loader:
        images = images.to(device)
        outputs = model(images)
        preds = torch.sigmoid(outputs) > 0.5

        # Convert tensors to numpy and plot
        break  # Show just 1 batch

"""Visualize Predictions"""

import matplotlib.pyplot as plt
import torch.nn.functional as F

model.eval()
with torch.no_grad():
    for images, masks in train_loader:
        images = images.to(device)
        outputs = model(images)
        preds = torch.sigmoid(outputs)
        preds = (preds > 0.5).float()

        # Move to CPU for visualization
        images = images.cpu().numpy()
        masks = masks.cpu().numpy()
        preds = preds.cpu().numpy()

        # Plot first 4 predictions
        for i in range(min(4, len(images))):
            plt.figure(figsize=(12, 3))

            plt.subplot(1, 3, 1)
            plt.imshow(np.transpose(images[i], (1, 2, 0)))
            plt.title("Satellite Image")
            plt.axis('off')

            plt.subplot(1, 3, 2)
            plt.imshow(masks[i][0], cmap='gray')
            plt.title("Ground Truth")
            plt.axis('off')

            plt.subplot(1, 3, 3)
            plt.imshow(preds[i][0], cmap='gray')
            plt.title("Predicted Mask")
            plt.axis('off')

            plt.show()
        break

torch.save(model.state_dict(), "unet_mumbai_roads.pth")

"""IoU and Dice Score Evaluation"""



"""Metric Functions"""

import torch

def compute_iou(pred, target, threshold=0.5, eps=1e-6):
    pred = (pred > threshold).float()
    target = target.float()
    intersection = (pred * target).sum(dim=(1, 2, 3))
    union = (pred + target).clamp(0, 1).sum(dim=(1, 2, 3))
    iou = (intersection + eps) / (union + eps)
    return iou.mean().item()

def compute_dice(pred, target, threshold=0.5, eps=1e-6):
    pred = (pred > threshold).float()
    target = target.float()
    intersection = (pred * target).sum(dim=(1, 2, 3))
    dice = (2 * intersection + eps) / (pred.sum(dim=(1,2,3)) + target.sum(dim=(1,2,3)) + eps)
    return dice.mean().item()

"""Training Loop With Validation"""

import torch
import torch.nn.functional as F

def iou_metric(pred, target, threshold=0.5):
    pred = (pred > threshold).float()
    intersection = (pred * target).sum()
    union = pred.sum() + target.sum() - intersection
    return (intersection + 1e-6) / (union + 1e-6)

num_epochs = 10

for epoch in range(num_epochs):
    # --- Training ---
    model.train()
    train_loss = 0.0

    for images, masks in train_loader:
        images, masks = images.to(device), masks.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = F.binary_cross_entropy_with_logits(outputs, masks)
        loss.backward()
        optimizer.step()

        train_loss += loss.item()

    # --- Validation ---
    model.eval()
    val_loss = 0.0
    iou_score = 0.0
    with torch.no_grad():
        for images, masks in val_loader:
            images, masks = images.to(device), masks.to(device)
            outputs = model(images)

            loss = F.binary_cross_entropy_with_logits(outputs, masks)
            val_loss += loss.item()

            preds = torch.sigmoid(outputs)
            iou_score += iou_metric(preds, masks).item()

    # --- Reporting ---
    n_train = len(train_loader)
    n_val = len(val_loader)
    print(f"Epoch {epoch+1}/{num_epochs} | "
          f"Train Loss: {train_loss/n_train:.4f} | "
          f"Val Loss: {val_loss/n_val:.4f} | "
          f"IoU: {iou_score/n_val:.4f}")



"""visualization during training

"""

import matplotlib.pyplot as plt

def visualize_prediction(image, mask, pred, epoch, sample_id=0):
    """
    Show satellite image, ground truth mask, and predicted mask.
    """
    image = image.cpu().permute(1, 2, 0).numpy()
    mask = mask.cpu().squeeze().numpy()
    pred = pred.cpu().squeeze().numpy()

    fig, axs = plt.subplots(1, 3, figsize=(12, 4))
    axs[0].imshow(image)
    axs[0].set_title("Satellite Image")
    axs[0].axis('off')

    axs[1].imshow(mask, cmap='gray')
    axs[1].set_title("Ground Truth Mask")
    axs[1].axis('off')

    axs[2].imshow(pred > 0.5, cmap='gray')
    axs[2].set_title("Predicted Mask (Binarized)")
    axs[2].axis('off')

    plt.suptitle(f"Epoch {epoch + 1} – Sample {sample_id}")
    plt.tight_layout()
    plt.show()

images, masks = next(iter(val_loader))
images, masks = images.to(device), masks.to(device)
with torch.no_grad():
    outputs = model(images)
    preds = torch.sigmoid(outputs)

visualize_prediction(images[0], masks[0], preds[0], epoch)

"""Save the Best Model"""

best_iou = 0.0

for epoch in range(num_epochs):
    # training and validation loops...

    if iou_score > best_iou:
        best_iou = iou_score
        torch.save(model.state_dict(), "best_unet_model.pth")
        print(f"✔️ Saved best model (Epoch {epoch+1}, IoU: {iou_score:.4f})")

"""Evaluate on Test Set"""

model.load_state_dict(torch.load("best_unet_model.pth"))
model.eval()
# compute IoU, Dice, visualize predictions etc. on test_loader

"""Augmentations"""

import albumentations as A
from albumentations.pytorch import ToTensorV2

train_transform = A.Compose([
    A.Resize(512, 512),
    A.HorizontalFlip(p=0.5),
    A.RandomBrightnessContrast(p=0.2),
    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=15, p=0.5),
    A.Normalize(),
    ToTensorV2()
])

"""Export Predictions"""

def save_predictions(model, dataloader, save_dir="predicted_masks"):
    os.makedirs(save_dir, exist_ok=True)
    model.eval()
    with torch.no_grad():
        for i, (images, _) in enumerate(dataloader):
            images = images.to(device)
            preds = torch.sigmoid(model(images)).cpu().numpy()
            for j in range(images.shape[0]):
                pred_mask = (preds[j, 0] > 0.5).astype(np.uint8) * 255
                Image.fromarray(pred_mask).save(f"{save_dir}/pred_{i*batch_size + j}.png")

